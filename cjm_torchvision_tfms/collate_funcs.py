"""Some custom collate functions."""

# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/03_collate_funcs.ipynb.

# %% auto 0
__all__ = ['resize_pad_collate']

# %% ../nbs/03_collate_funcs.ipynb 4
import math
from typing import Any, Dict, Optional, List, Tuple, Union
import random

import numpy as np

from PIL import Image

# Import PyTorch dependencies
import torch
import torchvision
torchvision.disable_beta_transforms_warning()
from torchvision.tv_tensors import BoundingBoxes, Mask
import torchvision.transforms.v2  as transforms
from torchvision.transforms.v2 import functional as TF

from .transforms import ResizeMax
from .utils import round_up_to_multiple

# %% ../nbs/03_collate_funcs.ipynb 6
def resize_pad_collate(batch, max_sz=256):
    """
    A custom collate function for a PyTorch DataLoader that performs:
    
    1) **Resize each (image, target) pair** so that the image's maximum dimension 
       does not exceed `max_sz` (using the custom `ResizeMax` transform).
    2) **Determine the largest image height and width in the batch**, 
       round them up to a multiple of 32, and then **randomly pad each image** 
       so they all share the same dimensions. BoundingBoxes and Masks in the 
       targets are updated accordingly.
    3) **Optionally perform a final Resize** to ensure all images have the 
       same shape (often a no-op if the padded size already matches).
    
    Args:
        batch (List[Tuple[Image, Dict]]): 
            A list of (image, target) pairs, where:
              - `image` can be a PIL Image, PyTorch tensor, or TorchVision `tv_tensors.Image`.
              - `target` is typically a dictionary containing bounding boxes (`"boxes"`), 
                masks (`"masks"`), and possibly other metadata.
        max_sz (int, optional): 
            The maximum size (height or width) for the resize step. Default: `256`.
    
    Returns:
        List[Tuple[Image, Dict]]: 
            A list of (image, target) pairs where each image is resized and padded 
            to the same dimensions, and any bounding boxes or masks have been 
            shifted/padded accordingly.
    """
    
    # Step 1) Resize each (image, target) pair so the image's largest side <= max_sz
    resized_pairs = []
    resize_max_transform = ResizeMax(max_sz=max_sz)
    for (img, tgt) in batch:
        new_img, new_tgt = resize_max_transform(img, tgt)
        resized_pairs.append((new_img, new_tgt))

    # Determine the largest height and width across all resized images
    raw_max_height, raw_max_width = 0, 0
    for (img, _) in resized_pairs:
        h, w = TF.get_size(img)
        raw_max_height = max(raw_max_height, h)
        raw_max_width = max(raw_max_width, w)

    # Round up these dimensions to the nearest multiple of 32
    final_max_height = round_up_to_multiple(raw_max_height, 32)
    final_max_width = round_up_to_multiple(raw_max_width, 32)

    # Step 2) Randomly pad each image (and its target data) to match
    #         (final_max_height, final_max_width)
    padded_pairs = []
    for (img, tgt) in resized_pairs:
        h, w = TF.get_size(img)
        
        # How much total padding is needed for height/width
        total_pad_h = final_max_height - h
        total_pad_w = final_max_width - w

        # Randomly distribute that padding (top vs. bottom, left vs. right)
        top_pad = random.randint(0, total_pad_h)
        bottom_pad = total_pad_h - top_pad
        left_pad = random.randint(0, total_pad_w)
        right_pad = total_pad_w - left_pad

        # Pad the image; TF.pad() expects [left, top, right, bottom]
        pad_img = TF.pad(img, [left_pad, top_pad, right_pad, bottom_pad])

        # Adjust target dictionary if present
        new_tgt = {}
        if isinstance(tgt, dict):
            # Shift bounding boxes
            if "boxes" in tgt and isinstance(tgt["boxes"], BoundingBoxes):
                boxes_out = TF.pad(tgt["boxes"], [left_pad, top_pad, right_pad, bottom_pad])
                # Update the bounding box canvas size
                boxes_out.canvas_size = (final_max_height, final_max_width)
                new_tgt["boxes"] = boxes_out

            # Pad masks
            if "masks" in tgt and isinstance(tgt["masks"], Mask):
                masks_out = TF.pad(tgt["masks"], [left_pad, top_pad, right_pad, bottom_pad])
                new_tgt["masks"] = masks_out

            # Copy over any other keys unchanged
            for k, v in tgt.items():
                if k not in ("boxes", "masks"):
                    new_tgt[k] = v
        else:
            # If targets are not a dictionary, handle or copy directly
            new_tgt = tgt

        padded_pairs.append((pad_img, new_tgt))

    # Step 3) Apply a final resize to ensure each image has 
    #         (final_max_height, final_max_width) dimensions.
    #         Often a no-op if already padded to the exact size.
    final_resize = transforms.Resize((final_max_height, final_max_width), antialias=True)
    final_pairs = []
    for (img, tgt) in padded_pairs:
        out_img, out_tgt = final_resize(img, tgt)
        final_pairs.append((out_img, out_tgt))

    return final_pairs
