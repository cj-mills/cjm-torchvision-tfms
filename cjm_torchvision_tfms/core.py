# AUTOGENERATED! DO NOT EDIT! File to edit: ../nbs/00_core.ipynb.

# %% auto 0
__all__ = ['ResizeMax', 'PadSquare', 'CustomTrivialAugmentWide']

# %% ../nbs/00_core.ipynb 4
from typing import Any, Dict, Optional, List, Tuple
import random

from cjm_pil_utils.core import stack_imgs
from cjm_pytorch_utils.core import pil_to_tensor, tensor_to_pil


from PIL import Image

# Import PyTorch dependencies
import torch
import torchvision
torchvision.disable_beta_transforms_warning()
from torchvision.datapoints import BoundingBox
from torchvision.utils import draw_bounding_boxes
import torchvision.transforms.v2  as transforms
from torchvision.transforms.v2 import functional as TF

# %% ../nbs/00_core.ipynb 8
class ResizeMax(transforms.Transform):
    """
    A PyTorch Transform class that resizes an image such that the maximum dimension 
    is equal to a specified size while maintaining the aspect ratio.
    
    Inherits from the PyTorch Transform class (transforms.Transform).

    Attributes:
    -----------
    max_sz : int
        The maximum size for any dimension (height or width) of the image.
    """
    
    def __init__(self, max_sz=256):
        """
        Initialize ResizeMax object with a specified max_sz. 

        Parameters:
        -----------
        max_sz : int, optional
            The maximum size for any dimension (height or width) of the image. 
            Default is 256.
        """
        # Call to the parent class (Transform) constructor
        super().__init__()

        # Set the maximum size for any dimension of the image
        self.max_sz = max_sz
        
    def _transform(self, inpt: Any, params: Dict[str, Any]):
        """
        Apply the ResizeMax transformation on an input image tensor.

        Parameters:
        -----------
        inpt : torch.Tensor
            The input image tensor to be resized.
        params : dict
            A dictionary of parameters. Not used in this method but is present for 
            compatibility with the parent's method signature.

        Returns:
        --------
        torch.Tensor
            The resized image tensor.
        """

        # Copy the input tensor to a new variable
        x = inpt

        # Get the width and height of the image tensor
        spatial_size = TF.get_spatial_size(x)

        # Calculate the size for the smaller dimension, such that the aspect ratio 
        # of the image is maintained when the larger dimension is resized to max_sz
        size = int(min(spatial_size) / (max(spatial_size) / self.max_sz))

        # Resize the image tensor with antialiasing for smoother output
        x = TF.resize(x, size=size, antialias=True)

        # Return the transformed (resized) image tensor
        return x

# %% ../nbs/00_core.ipynb 13
class PadSquare(transforms.Transform):
    """
    PadSquare is a PyTorch Transform class used to pad images to make them square. 
    Depending on the configuration, padding can be applied equally on both sides, 
    or can be randomly split between the two sides.
    
    Attributes:
        padding_mode (str): The method to use for padding. Default is 'constant'.
        fill (tuple): The RGB values to use for padding if padding_mode is 'constant'. Default is (123, 117, 104).
        shift (bool): If True, padding is randomly split between the two sides. If False, padding is equally applied. Default is True.
        pad_split (float): The proportion of padding applied to one side of the image. Only used when shift is True.
    """

    def __init__(self, padding_mode='constant', fill=(123, 117, 104), shift=True):
        """
        The constructor for PadSquare class.

        Parameters:
            padding_mode (str): The method to use for padding. Default is 'constant'.
            fill (tuple): The RGB values to use for padding if padding_mode is 'constant'. Default is (123, 117, 104).
            shift (bool): If True, padding is randomly split between the two sides. If False, padding is equally applied. Default is True.
        """
        super().__init__()
        self.padding_mode = padding_mode
        self.fill = fill
        self.shift = shift
        self.pad_split = None

    def forward(self, *inputs: Any) -> Any:
        """
        The forward method that sets up the padding split factor if 'shift' is True, 
        and then calls the superclass forward method.
        
        Parameters:
            *inputs (Any): The inputs to the forward method.

        Returns:
            Any: The result of the superclass forward method.
        """
        self.pad_split = random.random() if self.shift else None
        return super().forward(*inputs)

    def _transform(self, inpt: Any, params: Dict[str, Any]):
        """
        The _transform method that applies padding to the input to make it square.
        
        Parameters:
            inpt (Any): The input to be transformed.
            params (Dict[str, Any]): A dictionary of parameters for the transformation.

        Returns:
            Any: The transformed input.
        """
        x = inpt
        
        # Get the width and height of the image tensor
        h, w = TF.get_spatial_size(x)
        
        # If shift is true, padding is randomly split between two sides
        if self.shift:
            offset = (max(w, h) - min(w, h))
            pad_1 = int(offset*self.pad_split)
            pad_2 = offset - pad_1
            
            # The padding is applied to the shorter dimension of the image
            self.padding = [0, pad_1, 0, pad_2] if h < w else [pad_1, 0, pad_2, 0]
            padding = self.padding
        else:
            # If shift is false, padding is equally split between two sides
            offset = (max(w, h) - min(w, h)) // 2
            padding = [0, offset] if h < w else [offset, 0]
        
        # Apply the padding to the image
        x = TF.pad(x, padding=padding, padding_mode=self.padding_mode, fill=self.fill)
        
        return x

# %% ../nbs/00_core.ipynb 16
class CustomTrivialAugmentWide(torchvision.transforms.TrivialAugmentWide):
    def __init__(
        self,
        num_magnitude_bins: int = 31,
        interpolation: transforms.InterpolationMode = transforms.InterpolationMode.NEAREST,
        fill: Optional[List[float]] = None,
        op_meta: Optional[Dict[str, Tuple[torch.Tensor, bool]]] = None
    ) -> None:
        super().__init__(num_magnitude_bins, interpolation, fill)
        self.op_meta = op_meta if op_meta else super()._augmentation_space(num_bins)

    def _augmentation_space(self, num_bins: int) -> Dict[str, Tuple[torch.Tensor, bool]]:
        return self.op_meta
